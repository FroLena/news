import os
import asyncio
import json
import requests
from telethon import TelegramClient, events, types, functions
from openai import OpenAI
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import edge_tts

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
API_ID = int(os.environ.get('TG_API_ID'))
API_HASH = os.environ.get('TG_API_HASH')
OPENAI_KEY = os.environ.get('OPENAI_API_KEY')

SOURCE_CHANNELS = [
    'rian_ru', 'rentv_channel', 'breakingmash', 'bazabazon', 
    'shot_shot', 'ostorozhno_novosti', 'rbc_news'
]
DESTINATION = '@s_ostatok'

MAX_VIDEO_SIZE = 50 * 1024 * 1024 

# 2. OpenAI
print("–ò—Å–ø–æ–ª—å–∑—É—é OpenRouter...")
gpt_client = OpenAI(
    api_key=OPENAI_KEY, 
    base_url="https://openrouter.ai/api/v1"
)
AI_MODEL = "openai/gpt-4o-mini"
IMAGE_MODEL = "black-forest-labs/flux-1-schnell"

# 3. –ö–ª–∏–µ–Ω—Ç
client = TelegramClient('amvera_session', API_ID, API_HASH)
raw_text_cache = []
published_topics = []

# --- –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–ö–ò (–ü–†–Ø–ú–û–ô –ó–ê–ü–†–û–°) ---
async def generate_image(prompt_text):
    # –ß–∏—Å—Ç–∏–º –ø—Ä–æ–º–ø—Ç –æ—Ç –º—É—Å–æ—Ä–∞
    clean_prompt = prompt_text.replace('||', '').replace('R:', '').strip()
    print(f"üé® –†–∏—Å—É—é (Flux): {clean_prompt[:50]}...")
    
    url = "https://openrouter.ai/api/v1/images/generations"
    headers = {
        "Authorization": f"Bearer {OPENAI_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://amvera.ru",
        "X-Title": "NewsBot"
    }
    data = {
        "model": IMAGE_MODEL,
        "prompt": clean_prompt,
        "n": 1,
        "size": "1024x1024"
    }
    try:
        response = await asyncio.to_thread(requests.post, url, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['data'][0]['url']
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API OpenRouter ({response.status_code}): {response.text}")
            return None
    except Exception as e:
        print(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return None

# --- –ü–û–î–ö–ê–°–¢ (–¢–í–û–ô –ù–û–í–´–ô –ü–†–û–ú–ü–¢) ---
async def send_evening_podcast():
    print("üéô –ì–æ—Ç–æ–≤–ª—é –ø–æ–¥–∫–∞—Å—Ç...")
    try:
        history_posts = []
        async for message in client.iter_messages(DESTINATION, limit=30):
            if message.text: history_posts.append(message.text)
        
        if not history_posts: return
        full_text = "\n\n".join(history_posts[:20])

        # === –ü–†–û–ú–ü–¢ –ü–û–î–ö–ê–°–¢–ê ===
        system_prompt = (
            "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–∞–¥–∏–æ–≤–µ–¥—É—â–∏–π –∏—Ç–æ–≥–æ–≤–æ–≥–æ —à–æ—É ¬´–°—É—Ö–æ–π –æ—Å—Ç–∞—Ç–æ–∫¬ª.\n"
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –°–æ–∑–¥–∞—Ç—å —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –¥–µ–Ω—å.\n\n"
            "–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –¢–ï–ö–°–¢–£:\n"
            "1. –°–¢–†–£–ö–¢–£–†–ê: –í—Å—Ç—É–ø–ª–µ–Ω–∏–µ -> –ü–ª–∞–≤–Ω—ã–π —Ä–∞—Å—Å–∫–∞–∑ (3-5 –≥–ª–∞–≤–Ω—ã—Ö —Ç–µ–º) -> –ó–∞–∫–ª—é—á–µ–Ω–∏–µ.\n"
            "2. –°–¢–ò–õ–¨: –ñ–∏–≤–æ–π, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π, –Ω–µ–º–Ω–æ–≥–æ –∏—Ä–æ–Ω–∏—á–Ω—ã–π, –Ω–æ —É–≤–µ—Ä–µ–Ω–Ω—ã–π. –ò–∑–±–µ–≥–∞–π —Å—É—Ö–∏—Ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π ('–ü–µ—Ä–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å...', '–í—Ç–æ—Ä–∞—è –Ω–æ–≤–æ—Å—Ç—å...'). –ò—Å–ø–æ–ª—å–∑—É–π –ø–µ—Ä–µ—Ö–æ–¥—ã: '–¢–µ–º –≤—Ä–µ–º–µ–Ω–µ–º...', '–ù–µ –º–µ–Ω–µ–µ –≤–∞–∂–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ...', '–ê –Ω–∞–ø–æ—Å–ª–µ–¥–æ–∫...'.\n"
            "3. –ê–î–ê–ü–¢–ê–¶–ò–Ø –ü–û–î –û–ó–í–£–ß–ö–£: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–∂–Ω—ã–µ —Ü–∏—Ñ—Ä—ã (–ø–∏—à–∏ '–æ–∫–æ–ª–æ –º–∏–ª–ª–∏–æ–Ω–∞', –∞ –Ω–µ '984 321'), —É–±–µ—Ä–∏ —Å—Å—ã–ª–∫–∏, —Ö–µ—à—Ç–µ–≥–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã.\n"
            "4. –•–†–û–ù–û–ú–ï–¢–†–ê–ñ: –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω —á–∏—Ç–∞—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –∑–∞ 60-90 —Å–µ–∫—É–Ω–¥.\n\n"
            "–ù–ê–ß–ê–õ–û: '–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä. –í —ç—Ñ–∏—Ä–µ –°—É—Ö–æ–π –æ—Å—Ç–∞—Ç–æ–∫. –ü–æ–¥–≤–µ–¥–µ–º –∏—Ç–æ–≥–∏ —ç—Ç–æ–≥–æ –¥–Ω—è.'\n"
            "–ö–û–ù–ï–¶: '–¢–∞–∫–∏–º –±—ã–ª —ç—Ç–æ—Ç –¥–µ–Ω—å. –û—Å—Ç–∞–≤–∞–π—Ç–µ—Å—å —Å –Ω–∞–º–∏. –î–æ —Å–≤—è–∑–∏.'"
        )
        
        script = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": full_text}]
        ).choices[0].message.content.replace('*', '').replace('#', '')

        communicate = edge_tts.Communicate(script, "ru-RU-DmitryNeural")
        await communicate.save("podcast.mp3")
            
        await client.send_file(DESTINATION, "podcast.mp3", caption="üéô <b>–ò—Ç–æ–≥–∏ –¥–Ω—è</b>", parse_mode='html', voice_note=True)
        if os.path.exists("podcast.mp3"): os.remove("podcast.mp3")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–∞—Å—Ç–∞: {e}")

# --- AI –†–ï–î–ê–ö–¢–û–† (–¢–í–û–ô –ù–û–í–´–ô –ü–†–û–ú–ü–¢) ---
async def rewrite_news(text, history_topics):
    recent_history = history_topics[-5:] if len(history_topics) > 0 else []
    history_str = "\n".join([f"- {t}" for t in recent_history]) if recent_history else "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏."

    # === –ü–†–û–ú–ü–¢ –†–ï–î–ê–ö–¢–û–†–ê ===
    system_prompt = (
        f"–¢—ã ‚Äî –≥–ª–∞–≤–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ ¬´–°—É—Ö–æ–π –æ—Å—Ç–∞—Ç–æ–∫¬ª. –ò—Å—Ç–æ—Ä–∏—è —Ç–µ–º: {history_str}\n\n"
        f"–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê –°–¢–†–û–ì–û: –¢–ï–ö–°–¢ ||| –ü–†–û–ú–ü–¢_–ö–ê–†–¢–ò–ù–ö–ò\n\n"
        f"=== –ß–ê–°–¢–¨ 1: –¢–ï–ö–°–¢ (Russian HTML) ===\n"
        f"1. –§–ò–õ–¨–¢–†–´: –†–µ–∫–ª–∞–º–∞/–ü—Ä–æ–¥–∞–∂–∏/–ö–∞–∑–∏–Ω–æ -> –≤–µ—Ä–Ω–∏ —Å–ª–æ–≤–æ SKIP. –î—É–±–ª–∏–∫–∞—Ç—ã —Å–æ–±—ã—Ç–∏–π -> –≤–µ—Ä–Ω–∏ DUPLICATE.\n"
        f"2. –°–¢–ò–õ–¨ (–ò–Ω—Ñ–æ—Å—Ç–∏–ª—å): –ü–∏—à–∏ –∂–µ—Å—Ç–∫–æ, –∫–æ—Ä–æ—Ç–∫–æ, —Ñ–∞–∫—Ç—É—Ä–Ω–æ. –£–±–∏—Ä–∞–π –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞ ('—Å–æ–æ–±—â–∞–µ—Ç—Å—è —á—Ç–æ', '–∫–∞–∫ —Å—Ç–∞–ª–æ –∏–∑–≤–µ—Å—Ç–Ω–æ'). –°—Ä–∞–∑—É –∫ –¥–µ–ª—É.\n"
        f"3. –ó–ê–ì–û–õ–û–í–û–ö: –ü—Ä–∏–¥—É–º–∞–π —Ü–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –≤—ã–¥–µ–ª–∏ –µ–≥–æ –∂–∏—Ä–Ω—ã–º (<b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b>).\n"
        f"4. –°–¢–†–£–ö–¢–£–†–ê: –ó–∞–≥–æ–ª–æ–≤–æ–∫ -> 2-3 –∞–±–∑–∞—Ü–∞ —Å–∞–º–æ–π —Å—É—Ç–∏ -> –¶–∏—Ç–∞—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å, —á–µ—Ä–µ–∑ <i></i>) -> –í—ã–≤–æ–¥.\n"
        f"5. –í –ö–û–ù–¶–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: <blockquote><b>üìå –°—É—Ç—å:</b> [–æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, —Å–∞–º—ã–π –≥–ª–∞–≤–Ω—ã–π –≤—ã–≤–æ–¥]</blockquote>\n"
        f"6. –†–ï–ê–ö–¶–ò–ò: –í —Å–∞–º–æ–µ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ–±–∞–≤—å –∫–æ–¥ —Ä–µ–∞–∫—Ü–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä ||R:üî•|| (–í—ã–±–µ—Ä–∏: üî•, ü§°, ‚ö°Ô∏è, üò¢, üëç).\n"
        f"7. –û–ü–†–û–°–´: –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –≤—ã–∑—ã–≤–∞–µ—Ç —Å–ø–æ—Ä—ã, –¥–æ–±–∞–≤—å –≤ –∫–æ–Ω–µ—Ü ||POLL||.\n\n"
        f"=== –ß–ê–°–¢–¨ 2: –ü–†–û–ú–ü–¢ –ö–ê–†–¢–ò–ù–ö–ò (English) ===\n"
        f"- –û–ø–∏—à–∏ —Å—Ü–µ–Ω—É –∫–∞–∫ —Ä–µ–∂–∏—Å—Å–µ—Ä –∫–∏–Ω–æ. Style: 'Hyperrealistic documentary photo, award-winning journalism, cinematic lighting, 8k, highly detailed'.\n"
        f"- –ù–ï –ø–∏—à–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö.\n"
    )

    try:
        response = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text}]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ AI: {e}")
        return None

@client.on(events.NewMessage(chats=SOURCE_CHANNELS))
async def handler(event):
    text = event.message.message
    if not text: text = "" 
    if len(text) < 20: return

    short_hash = text[:100]
    if short_hash in raw_text_cache: return
    raw_text_cache.append(short_hash)
    if len(raw_text_cache) > 100: raw_text_cache.pop(0)

    try:
        chat = await event.get_chat()
        source_name = chat.title
    except:
        source_name = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª"
    
    print(f"üîé –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑: {source_name}")
    
    full_response = await rewrite_news(text, published_topics)
    if not full_response: return

    if "DUPLICATE" in full_response: 
        print("‚ùå –î—É–±–ª—å")
        return
    if "SKIP" in full_response: 
        print("üóë –†–µ–∫–ª–∞–º–∞")
        return

    # --- –ü–ê–†–°–ò–ù–ì ---
    raw_text = full_response
    image_prompt = None
    
    if "|||" in raw_text:
        parts = raw_text.split("|||")
        news_text = parts[0].strip()
        image_prompt = parts[1].strip()
    else:
        news_text = raw_text.strip()

    reaction = None
    if "||R:" in news_text:
        try:
            parts = news_text.split("||R:")
            subparts = parts[1].split("||")
            reaction = subparts[0].strip()
            news_text = subparts[1].strip()
            print(f"üòé –†–µ–∞–∫—Ü–∏—è: {reaction}")
        except: pass

    poll_data = None
    if "||POLL||" in news_text:
        try:
            p = news_text.split("||POLL||")
            news_text = p[0].strip()
            lines = p[1].strip().split('\n')
            if len(lines) >= 3: poll_data = {"q": lines[0], "o": [o for o in lines[1:] if o.strip()]}
        except: pass

    # Fallback (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∏–ª—å –∏–∑ —Ç–≤–æ–µ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)
    if not image_prompt and event.message.photo:
        print("‚ö†Ô∏è –ò–ò –∑–∞–±—ã–ª –ø—Ä–æ–º–ø—Ç. –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞–≤—Ç–æ-–ø—Ä–æ–º–ø—Ç...")
        base_prompt = news_text.replace('\n', ' ')[:100]
        image_prompt = f"Hyperrealistic documentary photo, award-winning journalism, cinematic lighting, 8k. Context: {base_prompt}"

    # --- –û–¢–ü–†–ê–í–ö–ê ---
    sent_msg = None
    try:
        has_video = event.message.video is not None
        
        if has_video:
            if event.message.file.size > MAX_VIDEO_SIZE:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
            else:
                path = await event.download_media()
                sent_msg = await client.send_file(DESTINATION, path, caption=news_text, parse_mode='html', supports_streaming=True)
                os.remove(path)
        
        elif image_prompt:
            img_url = await generate_image(image_prompt)
            if img_url:
                sent_msg = await client.send_file(DESTINATION, img_url, caption=news_text, parse_mode='html')
            else:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
        else:
            sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')

        if sent_msg and reaction:
            await asyncio.sleep(2)
            try:
                await client(functions.messages.SendReactionRequest(
                    peer=DESTINATION,
                    msg_id=sent_msg.id,
                    reaction=[types.ReactionEmoji(emoticon=reaction)]
                ))
            except: pass

        if poll_data:
            await asyncio.sleep(1)
            poll_media = types.InputMediaPoll(poll=types.Poll(id=1, question=poll_data["q"], answers=[types.PollAnswer(text=o, option=bytes([i])) for i, o in enumerate(poll_data["o"])]))
            await client.send_message(DESTINATION, file=poll_media)

        print("‚úÖ –ü–æ—Å—Ç –≥–æ—Ç–æ–≤!")
        published_topics.append(news_text[:100])
        if len(published_topics) > 10: published_topics.pop(0)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")

if __name__ == '__main__':
    print("üöÄ –°—Ç–∞—Ä—Ç...")
    client.start()
    scheduler = AsyncIOScheduler(event_loop=client.loop)
    scheduler.add_job(send_evening_podcast, 'cron', hour=18, minute=0)
    scheduler.start()
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! (Final User Prompts)")
    client.run_until_disconnected()
