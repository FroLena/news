import os
import asyncio
import json
import requests # –ü—Ä—è–º—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫
from telethon import TelegramClient, events, types, functions
from openai import OpenAI
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import edge_tts

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
API_ID = int(os.environ.get('TG_API_ID'))
API_HASH = os.environ.get('TG_API_HASH')
OPENAI_KEY = os.environ.get('OPENAI_API_KEY')

SOURCE_CHANNELS = [
    'rian_ru', 'rentv_channel', 'breakingmash', 'bazabazon', 
    'shot_shot', 'ostorozhno_novosti', 'rbc_news'
]
DESTINATION = '@s_ostatok'

MAX_VIDEO_SIZE = 50 * 1024 * 1024 

# 2. OpenAI
print("–ò—Å–ø–æ–ª—å–∑—É—é OpenRouter...")
gpt_client = OpenAI(
    api_key=OPENAI_KEY, 
    base_url="https://openrouter.ai/api/v1"
)
AI_MODEL = "openai/gpt-4o-mini"
IMAGE_MODEL = "black-forest-labs/flux-1-schnell"

# 3. –ö–ª–∏–µ–Ω—Ç
client = TelegramClient('amvera_session', API_ID, API_HASH)
raw_text_cache = []
published_topics = []

# --- –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–ö–ò (–ü–†–Ø–ú–û–ô –ó–ê–ü–†–û–°) ---
async def generate_image(prompt_text):
    print(f"üé® –†–∏—Å—É—é –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é: {prompt_text[:50]}...")
    url = "https://openrouter.ai/api/v1/images/generations"
    headers = {
        "Authorization": f"Bearer {OPENAI_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://amvera.ru",
        "X-Title": "NewsBot"
    }
    data = {
        "model": IMAGE_MODEL,
        "prompt": prompt_text,
        "n": 1,
        "size": "1024x1024"
    }
    try:
        response = await asyncio.to_thread(requests.post, url, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['data'][0]['url']
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API OpenRouter: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")
        return None

# --- –ü–û–î–ö–ê–°–¢ ---
async def send_evening_podcast():
    print("üéô –ì–æ—Ç–æ–≤–ª—é –ø–æ–¥–∫–∞—Å—Ç...")
    try:
        history_posts = []
        async for message in client.iter_messages(DESTINATION, limit=30):
            if message.text: history_posts.append(message.text)
        
        if not history_posts: return
        full_text = "\n\n".join(history_posts[:20])

        system_prompt = (
            "–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π '–°—É—Ö–æ–π –æ—Å—Ç–∞—Ç–æ–∫'. –°–¥–µ–ª–∞–π –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç.\n"
            "–¢–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—Å–ª—É—Ö."
        )
        script = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": full_text}]
        ).choices[0].message.content.replace('*', '').replace('#', '')

        communicate = edge_tts.Communicate(script, "ru-RU-DmitryNeural")
        await communicate.save("podcast.mp3")
            
        await client.send_file(DESTINATION, "podcast.mp3", caption="üéô <b>–ò—Ç–æ–≥–∏ –¥–Ω—è</b>", parse_mode='html', voice_note=True)
        if os.path.exists("podcast.mp3"): os.remove("podcast.mp3")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–∞—Å—Ç–∞: {e}")

# --- AI –†–ï–î–ê–ö–¢–û–† ---
async def rewrite_news(text, history_topics):
    recent_history = history_topics[-5:] if len(history_topics) > 0 else []
    history_str = "\n".join([f"- {t}" for t in recent_history]) if recent_history else "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏."

    system_prompt = (
        f"–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ò—Å—Ç–æ—Ä–∏—è: {history_str}\n\n"
        f"–û–¢–í–ï–¢ –í –§–û–†–ú–ê–¢–ï: –¢–ï–ö–°–¢ ||| –ü–†–û–ú–ü–¢_–ö–ê–†–¢–ò–ù–ö–ò\n\n"
        f"–ß–ê–°–¢–¨ 1 (–¢–ï–ö–°–¢):\n"
        f"- –†–µ–∫–ª–∞–º–∞ -> SKIP. –î—É–±–ª–∏ -> DUPLICATE.\n"
        f"- –°–æ–∫—Ä–∞—Ç–∏ —Å—É—Ç—å. –í –∫–æ–Ω—Ü–µ: <blockquote><b>üìå –°—É—Ç—å:</b> [–≤—ã–≤–æ–¥]</blockquote>\n"
        f"- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–±–∞–≤—å —ç–º–æ–¥–∑–∏-—Ä–µ–∞–∫—Ü–∏—é –≤ —Å–∞–º–æ–µ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ||R:üî•||.\n"
        f"  (–í–∞—Ä–∏–∞–Ω—Ç—ã: ||R:üî•||, ||R:ü§°||, ||R:‚ö°Ô∏è||, ||R:üò¢||, ||R:üëç||)\n"
        f"- –ï—Å–ª–∏ —Ç–µ–º–∞ –æ—Å—Ç—Ä–∞—è ‚Äî –¥–æ–±–∞–≤—å ||POLL|| –≤ –∫–æ–Ω–µ—Ü.\n\n"
        f"–ß–ê–°–¢–¨ 2 (–ü–†–û–ú–ü–¢ –ö–ê–†–¢–ò–ù–ö–ò):\n"
        f"- English only.\n"
        f"- Style: 'Hyperrealistic documentary photo, cinematic lighting, 8k'."
    )

    try:
        response = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text}]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ AI: {e}")
        return None

@client.on(events.NewMessage(chats=SOURCE_CHANNELS))
async def handler(event):
    text = event.message.message
    if not text: text = "" 
    if len(text) < 20: return

    short_hash = text[:100]
    if short_hash in raw_text_cache: return
    raw_text_cache.append(short_hash)
    if len(raw_text_cache) > 100: raw_text_cache.pop(0)

    print(f"üîé –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏...")
    
    full_response = await rewrite_news(text, published_topics)
    if not full_response: return

    if "DUPLICATE" in full_response: return
    if "SKIP" in full_response: return

    # --- –ü–ê–†–°–ò–ù–ì ---
    news_text = full_response
    image_prompt = None
    
    # 1. –û—Ç–¥–µ–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –æ—Ç —Ç–µ–∫—Å—Ç–∞
    if "|||" in full_response:
        parts = full_response.split("|||")
        news_text = parts[0].strip()
        image_prompt = parts[1].strip()
    else:
        # Fallback
        if event.message.photo:
            base_prompt = news_text.split('.')[0] if '.' in news_text else "News"
            image_prompt = f"Hyperrealistic documentary photo reflecting: {base_prompt}. Cinematic, 8k."
            news_text = full_response

    # 2. –ò—â–µ–º –†–µ–∞–∫—Ü–∏—é (–í–û–¢ –û–ù–ê!)
    reaction = None
    if "||R:" in news_text:
        try:
            parts = news_text.split("||R:")
            # –û–±—ã—á–Ω–æ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫: "||R:üî•|| –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏..."
            # parts[0] –ø—É—Å—Ç–∞—è, parts[1] "üî•|| –¢–µ–∫—Å—Ç..."
            subparts = parts[1].split("||")
            reaction = subparts[0].strip() # üî•
            news_text = subparts[1].strip() # –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç
            print(f"üòé –ù–∞–π–¥–µ–Ω–∞ —Ä–µ–∞–∫—Ü–∏—è: {reaction}")
        except:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∞–∫—Ü–∏–∏")

    # 3. –ò—â–µ–º –û–ø—Ä–æ—Å
    poll_data = None
    if "||POLL||" in news_text:
        try:
            p = news_text.split("||POLL||")
            news_text = p[0].strip()
            lines = p[1].strip().split('\n')
            if len(lines) >= 3: poll_data = {"q": lines[0], "o": [o for o in lines[1:] if o.strip()]}
        except: pass

    # --- –û–¢–ü–†–ê–í–ö–ê ---
    sent_msg = None
    try:
        has_video = event.message.video is not None
        
        if has_video:
            if event.message.file.size > MAX_VIDEO_SIZE:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
            else:
                path = await event.download_media()
                sent_msg = await client.send_file(DESTINATION, path, caption=news_text, parse_mode='html', supports_streaming=True)
                os.remove(path)
        elif image_prompt:
            img_url = await generate_image(image_prompt)
            if img_url:
                sent_msg = await client.send_file(DESTINATION, img_url, caption=news_text, parse_mode='html')
            else:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
        else:
            sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')

        # --- –°–¢–ê–í–ò–ú –†–ï–ê–ö–¶–ò–Æ ---
        if sent_msg and reaction:
            await asyncio.sleep(2) # –î–∞–µ–º —Ç–µ–ª–µ–≥—Ä–∞–º—É –≤—Ä–µ–º—è "–æ—Å–æ–∑–Ω–∞—Ç—å" —Å–æ–æ–±—â–µ–Ω–∏–µ
            try:
                await client(functions.messages.SendReactionRequest(
                    peer=DESTINATION,
                    msg_id=sent_msg.id,
                    reaction=[types.ReactionEmoji(emoticon=reaction)]
                ))
                print(f"‚úÖ –†–µ–∞–∫—Ü–∏—è {reaction} –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞!")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–∞–∫—Ü–∏—é: {e}")

        # --- –°–¢–ê–í–ò–ú –û–ü–†–û–° ---
        if poll_data:
            await asyncio.sleep(1)
            poll_media = types.InputMediaPoll(poll=types.Poll(id=1, question=poll_data["q"], answers=[types.PollAnswer(text=o, option=bytes([i])) for i, o in enumerate(poll_data["o"])]))
            await client.send_message(DESTINATION, file=poll_media)

        published_topics.append(news_text[:100])
        if len(published_topics) > 10: published_topics.pop(0)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")

if __name__ == '__main__':
    print("üöÄ –°—Ç–∞—Ä—Ç...")
    client.start()
    scheduler = AsyncIOScheduler(event_loop=client.loop)
    scheduler.add_job(send_evening_podcast, 'cron', hour=18, minute=0)
    scheduler.start()
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! (Reactions + Flux Fix)")
    client.run_until_disconnected()
