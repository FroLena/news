import os
import asyncio
import json
import requests # <--- –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ø—Ä—è–º–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
from telethon import TelegramClient, events, types, functions
from openai import OpenAI
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import edge_tts

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
API_ID = int(os.environ.get('TG_API_ID'))
API_HASH = os.environ.get('TG_API_HASH')
OPENAI_KEY = os.environ.get('OPENAI_API_KEY')

SOURCE_CHANNELS = [
    'rian_ru', 'rentv_channel', 'breakingmash', 'bazabazon', 
    'shot_shot', 'ostorozhno_novosti', 'rbc_news'
]
DESTINATION = '@s_ostatok'

MAX_VIDEO_SIZE = 50 * 1024 * 1024 

# 2. OpenAI (–î–ª—è —Ç–µ–∫—Å—Ç–∞)
print("–ò—Å–ø–æ–ª—å–∑—É—é OpenRouter...")
gpt_client = OpenAI(
    api_key=OPENAI_KEY, 
    base_url="https://openrouter.ai/api/v1"
)
AI_MODEL = "openai/gpt-4o-mini"
# –ú–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫
IMAGE_MODEL = "black-forest-labs/flux-1-schnell"

# 3. –ö–ª–∏–µ–Ω—Ç
client = TelegramClient('amvera_session', API_ID, API_HASH)
raw_text_cache = []
published_topics = []

# --- –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–ö–ò (–ü–†–Ø–ú–û–ô –ó–ê–ü–†–û–°) ---
async def generate_image(prompt_text):
    print(f"üé® –†–∏—Å—É—é –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é (Direct Request): {prompt_text[:50]}...")
    
    url = "https://openrouter.ai/api/v1/images/generations"
    
    headers = {
        "Authorization": f"Bearer {OPENAI_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://amvera.ru", # OpenRouter –ø—Ä–æ—Å–∏—Ç —ç—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        "X-Title": "NewsBot"
    }
    
    data = {
        "model": IMAGE_MODEL,
        "prompt": prompt_text,
        "n": 1,
        "size": "1024x1024" # Flux —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ –≤—Å–µ–≥–æ —Å –∫–≤–∞–¥—Ä–∞—Ç–æ–º
    }

    try:
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –±–æ—Ç–∞
        response = await asyncio.to_thread(requests.post, url, headers=headers, json=data)
        
        if response.status_code == 200:
            result = response.json()
            image_url = result['data'][0]['url']
            print("üé® –ö–∞—Ä—Ç–∏–Ω–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
            return image_url
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API OpenRouter: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")
        return None

# --- –ü–û–î–ö–ê–°–¢ ---
async def send_evening_podcast():
    print("üéô –ì–æ—Ç–æ–≤–ª—é –ø–æ–¥–∫–∞—Å—Ç...")
    try:
        history_posts = []
        async for message in client.iter_messages(DESTINATION, limit=30):
            if message.text: history_posts.append(message.text)
        
        if not history_posts: return

        full_text = "\n\n".join(history_posts[:20])

        system_prompt = (
            "–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π '–°—É—Ö–æ–π –æ—Å—Ç–∞—Ç–æ–∫'. –°–¥–µ–ª–∞–π –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç.\n"
            "–°—Ç–∏–ª—å: –°–ø–æ–∫–æ–π–Ω—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π.\n"
            "–¢–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—Å–ª—É—Ö."
        )
        
        script = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": full_text}]
        ).choices[0].message.content.replace('*', '').replace('#', '')

        communicate = edge_tts.Communicate(script, "ru-RU-DmitryNeural")
        await communicate.save("podcast.mp3")
            
        await client.send_file(
            DESTINATION, "podcast.mp3", 
            caption="üéô <b>–ò—Ç–æ–≥–∏ –¥–Ω—è</b>", parse_mode='html', voice_note=True
        )
        if os.path.exists("podcast.mp3"): os.remove("podcast.mp3")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–∞—Å—Ç–∞: {e}")

# --- AI –†–ï–î–ê–ö–¢–û–† ---
async def rewrite_news(text, history_topics):
    recent_history = history_topics[-5:] if len(history_topics) > 0 else []
    history_str = "\n".join([f"- {t}" for t in recent_history]) if recent_history else "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏."

    system_prompt = (
        f"–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ò—Å—Ç–æ—Ä–∏—è: {history_str}\n\n"
        f"–û–ß–ï–ù–¨ –í–ê–ñ–ù–û: –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ –î–í–£–• —á–∞—Å—Ç–µ–π, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–∞–º–∏ |||\n"
        f"–ß–∞—Å—Ç—å 1: –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ (HTML)\n"
        f"–ß–∞—Å—Ç—å 2: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ (English)\n\n"
        f"–ü–†–ê–í–ò–õ–ê –¢–ï–ö–°–¢–ê:\n"
        f"- –†–µ–∫–ª–∞–º–∞ -> SKIP. –î—É–±–ª–∏ -> DUPLICATE.\n"
        f"- –°–æ–∫—Ä–∞—Ç–∏ —Å—É—Ç—å. –í –∫–æ–Ω—Ü–µ: <blockquote><b>üìå –°—É—Ç—å:</b> [–≤—ã–≤–æ–¥]</blockquote>\n"
        f"- –û—Å—Ç—Ä—ã–µ —Ç–µ–º—ã: ||R:üî•|| –≤ –Ω–∞—á–∞–ª–æ, ||POLL|| –≤ –∫–æ–Ω–µ—Ü.\n\n"
        f"–ü–†–ê–í–ò–õ–ê –ö–ê–†–¢–ò–ù–ö–ò (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û):\n"
        f"- –ü—Ä–æ–º–ø—Ç —Å—Ç—Ä–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º.\n"
        f"- –°—Ç–∏–ª—å: 'Hyperrealistic documentary photo, cinematic lighting, 8k'.\n"
        f"- –ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞:\n"
        f"–ü–æ–∂–∞—Ä –Ω–∞ —Å–∫–ª–∞–¥–µ... ||| A photo of firefighters at night in Moscow, smoke, orange fire lights, wet asphalt."
    )

    try:
        response = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ AI: {e}")
        return None

@client.on(events.NewMessage(chats=SOURCE_CHANNELS))
async def handler(event):
    text = event.message.message
    if not text: text = "" 
    if len(text) < 20: return

    short_hash = text[:100]
    if short_hash in raw_text_cache: return
    raw_text_cache.append(short_hash)
    if len(raw_text_cache) > 100: raw_text_cache.pop(0)

    chat_title = event.chat.title if hasattr(event.chat, 'title') else str(event.chat_id)
    print(f"üîé –û–±—Ä–∞–±–æ—Ç–∫–∞: {chat_title}")
    
    full_response = await rewrite_news(text, published_topics)
    if not full_response: return

    print(f"ü§ñ –û—Ç–≤–µ—Ç AI (–Ω–∞—á–∞–ª–æ): {full_response[:100]}...")

    if "DUPLICATE" in full_response:
        print(f"‚ùå –î—É–±–ª—å")
        return
    if "SKIP" in full_response:
        print(f"üóë –†–µ–∫–ª–∞–º–∞")
        return

    # –ü–∞—Ä—Å–∏–Ω–≥
    news_text = full_response
    image_prompt = None
    
    if "|||" in full_response:
        parts = full_response.split("|||")
        news_text = parts[0].strip()
        image_prompt = parts[1].strip()
        print("‚úÖ –ü—Ä–æ–º–ø—Ç –Ω–∞–π–¥–µ–Ω!")
    else:
        # Fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        if event.message.photo:
            print("‚ö†Ô∏è –ò–ò –∑–∞–±—ã–ª –ø—Ä–æ–º–ø—Ç! –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞–≤—Ç–æ-–ø—Ä–æ–º–ø—Ç...")
            base_prompt = news_text.split('.')[0] if '.' in news_text else news_text[:50]
            # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é –¥–µ–ª–∞—Ç—å —Å–ª–æ–∂–Ω–æ –±–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫, –Ω–∞–¥–µ–µ–º—Å—è —á—Ç–æ Flux –ø–æ–π–º–µ—Ç –∏–ª–∏ –≤–æ–∑—å–º–µ–º –ø—Ä–æ—Å—Ç–æ "Breaking news" —Å—Ç–∏–ª—å
            # –õ—É—á—à–µ –ø–æ–ø—Ä–æ—Å–∏—Ç—å GPT –ø–µ—Ä–µ–≤–µ—Å—Ç–∏, –Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–æ—Å—Ç–æ —Å–¥–µ–ª–∞–µ–º –æ–±—â–∏–π –ø—Ä–æ–º–ø—Ç
            image_prompt = f"Hyperrealistic documentary photo reflecting the news topic. Cinematic lighting, 8k. Context: {base_prompt}"
            news_text = full_response
        else:
            news_text = full_response

    # –î–æ–ø—ã
    poll_data = None
    reaction = None
    if "||R:" in news_text:
        try:
            p = news_text.split("||R:")
            sub = p[1].split("||")
            reaction = sub[0].strip()
            news_text = sub[1].strip()
        except: pass
    if "||POLL||" in news_text:
        try:
            p = news_text.split("||POLL||")
            news_text = p[0].strip()
            lines = p[1].strip().split('\n')
            if len(lines) >= 3: poll_data = {"q": lines[0], "o": [o for o in lines[1:] if o.strip()]}
        except: pass

    # –û—Ç–ø—Ä–∞–≤–∫–∞
    sent_msg = None
    try:
        has_video = event.message.video is not None
        
        if has_video:
            if event.message.file.size > MAX_VIDEO_SIZE:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
            else:
                print("üé• –í–∏–¥–µ–æ... (–û—Ä–∏–≥–∏–Ω–∞–ª)")
                path = await event.download_media()
                sent_msg = await client.send_file(DESTINATION, path, caption=news_text, parse_mode='html', supports_streaming=True)
                os.remove(path)
        
        elif image_prompt:
            img_url = await generate_image(image_prompt)
            if img_url:
                sent_msg = await client.send_file(DESTINATION, img_url, caption=news_text, parse_mode='html')
            else:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
        
        else:
            sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')

        if sent_msg and reaction:
            await asyncio.sleep(2)
            try: await client(functions.messages.SendReactionRequest(peer=DESTINATION, msg_id=sent_msg.id, reaction=[types.ReactionEmoji(emoticon=reaction)]))
            except: pass
        if poll_data:
            await asyncio.sleep(1)
            poll_media = types.InputMediaPoll(poll=types.Poll(id=1, question=poll_data["q"], answers=[types.PollAnswer(text=o, option=bytes([i])) for i, o in enumerate(poll_data["o"])]))
            await client.send_message(DESTINATION, file=poll_media)

        print("‚úÖ –ü–æ—Å—Ç –≥–æ—Ç–æ–≤!")
        published_topics.append(news_text[:100])
        if len(published_topics) > 10: published_topics.pop(0)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")

if __name__ == '__main__':
    print("üöÄ –°—Ç–∞—Ä—Ç...")
    client.start()
    scheduler = AsyncIOScheduler(event_loop=client.loop)
    scheduler.add_job(send_evening_podcast, 'cron', hour=18, minute=0)
    scheduler.start()
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! (Fixed: 405 Error)")
    client.run_until_disconnected()
