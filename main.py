import os
import asyncio
from telethon import TelegramClient, events, types, functions
from openai import OpenAI
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import edge_tts

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
API_ID = int(os.environ.get('TG_API_ID'))
API_HASH = os.environ.get('TG_API_HASH')
OPENAI_KEY = os.environ.get('OPENAI_API_KEY')

SOURCE_CHANNELS = [
    'rian_ru', 'rentv_channel', 'breakingmash', 'bazabazon', 
    'shot_shot', 'ostorozhno_novosti', 'rbc_news'
]
DESTINATION = '@s_ostatok' # –¢–í–û–ô –Æ–ó–ï–†–ù–ï–ô–ú

MAX_VIDEO_SIZE = 50 * 1024 * 1024 

# 2. OpenAI (OpenRouter –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫)
print("–ò—Å–ø–æ–ª—å–∑—É—é OpenRouter...")
gpt_client = OpenAI(
    api_key=OPENAI_KEY, 
    base_url="https://openrouter.ai/api/v1"
)
# –ú–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—Å—Ç–∞
AI_MODEL = "openai/gpt-4o-mini"
# –ú–æ–¥–µ–ª—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ (–ë—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è)
IMAGE_MODEL = "black-forest-labs/flux-1-schnell"

# 3. –ö–ª–∏–µ–Ω—Ç
client = TelegramClient('amvera_session', API_ID, API_HASH)
raw_text_cache = []
published_topics = []

# --- –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–ö–ò (FLUX HYPERREALISM) ---
async def generate_image(prompt_text):
    print(f"üé® –†–∏—Å—É—é –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é: {prompt_text[:50]}...")
    try:
        # Flux –ª—é–±–∏—Ç –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ –∏–ª–∏ —Å–ª–µ–≥–∫–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã.
        # 1024x1024 - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞.
        response = gpt_client.images.generate(
            model=IMAGE_MODEL,
            prompt=prompt_text,
            n=1,
            size="1024x1024"
        )
        image_url = response.data[0].url
        return image_url
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")
        return None

# --- –ü–û–î–ö–ê–°–¢ (EDGE TTS) ---
async def send_evening_podcast():
    print("üéô –ì–æ—Ç–æ–≤–ª—é –ø–æ–¥–∫–∞—Å—Ç...")
    try:
        history_posts = []
        async for message in client.iter_messages(DESTINATION, limit=30):
            if message.text: history_posts.append(message.text)
        
        if not history_posts: return

        full_text = "\n\n".join(history_posts[:20])

        system_prompt = (
            "–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π '–°—É—Ö–æ–π –æ—Å—Ç–∞—Ç–æ–∫'. –°–¥–µ–ª–∞–π –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (3-5 –Ω–æ–≤–æ—Å—Ç–µ–π).\n"
            "–°—Ç–∏–ª—å: –°–ø–æ–∫–æ–π–Ω—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π.\n"
            "–¢–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—Å–ª—É—Ö."
        )
        
        script = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": full_text}]
        ).choices[0].message.content.replace('*', '').replace('#', '')

        communicate = edge_tts.Communicate(script, "ru-RU-DmitryNeural")
        await communicate.save("podcast.mp3")
            
        await client.send_file(
            DESTINATION, "podcast.mp3", 
            caption="üéô <b>–ò—Ç–æ–≥–∏ –¥–Ω—è</b>", parse_mode='html', voice_note=True
        )
        if os.path.exists("podcast.mp3"): os.remove("podcast.mp3")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–∞—Å—Ç–∞: {e}")

# --- AI –†–ï–î–ê–ö–¢–û–† + –ü–†–û–ú–ü–¢-–ò–ù–ñ–ï–ù–ï–† ---
async def rewrite_news(text, history_topics):
    recent_history = history_topics[-5:] if len(history_topics) > 0 else []
    history_str = "\n".join([f"- {t}" for t in recent_history]) if recent_history else "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏."

    # === –ù–û–í–´–ô, –£–°–ò–õ–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ ===
    system_prompt = (
        f"–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä –∏ –∞—Ä—Ç-–¥–∏—Ä–µ–∫—Ç–æ—Ä. –ò—Å—Ç–æ—Ä–∏—è: {history_str}\n\n"
        f"–ó–ê–î–ê–ß–ê: –í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –¢–ï–ö–°–¢ ||| –ü–†–û–ú–ü–¢_–î–õ–Ø_–ö–ê–†–¢–ò–ù–ö–ò\n\n"
        f"1. –¢–ï–ö–°–¢ (HTML):\n"
        f"   - –†–µ–∫–ª–∞–º–∞ -> SKIP. –î—É–±–ª–∏ -> DUPLICATE.\n"
        f"   - –°–æ–∫—Ä–∞—Ç–∏ —Å—É—Ç—å. –í –∫–æ–Ω—Ü–µ: <blockquote><b>üìå –°—É—Ç—å:</b> [–≤—ã–≤–æ–¥]</blockquote>\n"
        f"   - –û—Å—Ç—Ä—ã–µ —Ç–µ–º—ã: ||R:üî•|| –≤ –Ω–∞—á–∞–ª–æ, ||POLL|| –≤ –∫–æ–Ω–µ—Ü.\n\n"
        f"2. –ü–†–û–ú–ü–¢_–î–õ–Ø_–ö–ê–†–¢–ò–ù–ö–ò (English) --- –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:\n"
        f"   - –¢–≤–æ—è —Ü–µ–ª—å: —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –ì–ò–ü–ï–†–†–ï–ê–õ–ò–°–¢–ò–ß–ù–û–ô, –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–Ω–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –ø–µ—Ä–µ–¥–∞—é—â–µ–π —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏.\n"
        f"   - –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∏–ª—å: 'A documentary photograph, award-winning photojournalism, cinematic lighting, highly detailed, 8k resolution, realistic texture'.\n"
        f"   - –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è: –û–ø–∏—à–∏ –≥–ª–∞–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ, –≤—Ä–µ–º—è —Å—É—Ç–æ–∫, –ø–æ–≥–æ–¥—É, –∞—Ç–º–æ—Å—Ñ–µ—Ä—É (–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–∞—è, —Å–ø–æ–∫–æ–π–Ω–∞—è, –º—Ä–∞—á–Ω–∞—è). –û–ø–∏—à–∏ –∫–ª—é—á–µ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã —Å—Ü–µ–Ω—ã –∏ —Ñ–æ–Ω.\n"
        f"   - –ó–ê–ü–†–ï–¢: –ù–∏–∫–∞–∫–∏—Ö –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–π, –º—É–ª—å—Ç–∏–∫–æ–≤, 3D-—Ä–µ–Ω–¥–µ—Ä–æ–≤ –∏–ª–∏ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π. –¢–æ–ª—å–∫–æ —Å—É—Ä–æ–≤—ã–π —Ä–µ–∞–ª–∏–∑–º.\n"
        f"   - –ü—Ä–∏–º–µ—Ä: 'A documentary photograph of firefighters battling a massive warehouse fire at night in Moscow. Huge orange flames, smoke billowing, wet asphalt reflecting lights, exhausted firefighters with hoses. Cinematic, gritty, highly detailed.'\n"
        f"   - –ü–†–û–ú–ü–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ù–ê –ê–ù–ì–õ–ò–ô–°–ö–û–ú."
    )

    try:
        response = gpt_client.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ AI: {e}")
        return None

@client.on(events.NewMessage(chats=SOURCE_CHANNELS))
async def handler(event):
    text = event.message.message
    if not text: text = "" 
    if len(text) < 20: return

    short_hash = text[:100]
    if short_hash in raw_text_cache: return
    raw_text_cache.append(short_hash)
    if len(raw_text_cache) > 100: raw_text_cache.pop(0)

    print(f"üîé –û–±—Ä–∞–±–æ—Ç–∫–∞: {event.chat.username}")
    
    full_response = await rewrite_news(text, published_topics)
    if not full_response: return

    if "DUPLICATE" in full_response:
        print(f"‚ùå –î—É–±–ª—å")
        return
    if "SKIP" in full_response:
        print(f"üóë –†–µ–∫–ª–∞–º–∞")
        return

    # –ü–∞—Ä—Å–∏–Ω–≥ (–¢–ï–ö–°–¢ ||| –ü–†–û–ú–ü–¢)
    news_text = full_response
    image_prompt = None
    if "|||" in full_response:
        parts = full_response.split("|||")
        news_text = parts[0].strip()
        image_prompt = parts[1].strip()
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–ø–æ–≤
    poll_data = None
    reaction = None
    if "||R:" in news_text:
        try:
            p = news_text.split("||R:")
            sub = p[1].split("||")
            reaction = sub[0].strip()
            news_text = sub[1].strip()
        except: pass
    if "||POLL||" in news_text:
        try:
            p = news_text.split("||POLL||")
            news_text = p[0].strip()
            lines = p[1].strip().split('\n')
            if len(lines) >= 3: poll_data = {"q": lines[0], "o": [o for o in lines[1:] if o.strip()]}
        except: pass

    # –û—Ç–ø—Ä–∞–≤–∫–∞
    sent_msg = None
    try:
        has_video = event.message.video is not None
        
        # 1. –í–ò–î–ï–û -> –û—Ä–∏–≥–∏–Ω–∞–ª
        if has_video:
            if event.message.file.size > MAX_VIDEO_SIZE:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
            else:
                print("üé• –í–∏–¥–µ–æ... (–û—Ä–∏–≥–∏–Ω–∞–ª)")
                path = await event.download_media()
                sent_msg = await client.send_file(DESTINATION, path, caption=news_text, parse_mode='html', supports_streaming=True)
                os.remove(path)
        
        # 2. –§–û–¢–û/–¢–ï–ö–°–¢ -> –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (Flux Hyperrealism)
        elif image_prompt:
            img_url = await generate_image(image_prompt)
            if img_url:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ —Ñ–æ—Ç–æ –ø–æ —Å—Å—ã–ª–∫–µ
                sent_msg = await client.send_file(DESTINATION, img_url, caption=news_text, parse_mode='html')
            else:
                sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')
        
        else:
            sent_msg = await client.send_message(DESTINATION, news_text, parse_mode='html')

        # –î–æ–ø—ã
        if sent_msg and reaction:
            await asyncio.sleep(2)
            try: await client(functions.messages.SendReactionRequest(peer=DESTINATION, msg_id=sent_msg.id, reaction=[types.ReactionEmoji(emoticon=reaction)]))
            except: pass
        if poll_data:
            await asyncio.sleep(1)
            poll_media = types.InputMediaPoll(poll=types.Poll(id=1, question=poll_data["q"], answers=[types.PollAnswer(text=o, option=bytes([i])) for i, o in enumerate(poll_data["o"])]))
            await client.send_message(DESTINATION, file=poll_media)

        print("‚úÖ –ü–æ—Å—Ç –≥–æ—Ç–æ–≤!")
        published_topics.append(news_text[:100])
        if len(published_topics) > 10: published_topics.pop(0)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")

if __name__ == '__main__':
    print("üöÄ –°—Ç–∞—Ä—Ç...")
    client.start()
    scheduler = AsyncIOScheduler(event_loop=client.loop)
    scheduler.add_job(send_evening_podcast, 'cron', hour=18, minute=0)
    scheduler.start()
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! (Flux: Hyperrealistic News Photos)")
    client.run_until_disconnected()
